{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "681da3a6-1d50-414f-be7a-fa04af7146b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8ee41a0-7902-4145-8ebf-cafab737903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "502713e7-47ba-4a70-a2ce-4ecfe6ae560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "stops = stopwords.words('english')\n",
    "stops.extend([\"i'm\", \"he's\", \"i've\", \"i'll\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb20ab0a-9c51-4fdb-8666-cd4e620031de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(rows):\n",
    "    for row in rows:\n",
    "        doc = nlp(row['Text'])\n",
    "        row['tokens'] = []\n",
    "        for token in doc:\n",
    "            if token.pos_ != 'PUNCT' and token.is_stop is False:\n",
    "                tokens = dict()\n",
    "                tokens['word'] = token.text\n",
    "                tokens['pos'] = token.pos_\n",
    "                tokens['lemma'] = token.lemma_\n",
    "                row['tokens'].append(tokens)\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a73ba5ba-ce45-4311-bfb8-91f8abeef1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(rows):\n",
    "    rows = parse(rows)\n",
    "    for row in rows:\n",
    "        pos_distribution = dict()\n",
    "        for token in row['tokens']:\n",
    "            if token['pos'] in pos_distribution.keys():\n",
    "                pos_distribution[token['pos']] += 1\n",
    "            else:\n",
    "                pos_distribution[token['pos']] = 1\n",
    "        row['pos'] = pos_distribution\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1db9107c-a199-4d41-88a9-8047faf0dc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phrase_len(rows):\n",
    "    for row in rows:\n",
    "        phrase = row['Text']\n",
    "        words = [w.lower() for w in word_tokenize(phrase) if w.isalpha()]\n",
    "        row['len'] = len(words)\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70903fc9-a841-49be-ad11-fbc1ea11dc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_order(sent):\n",
    "    d = nlp(sent)\n",
    "    roots = [token for token in d if token.head == token]\n",
    "    orders = []\n",
    "    for root in roots:\n",
    "        d = {}\n",
    "        d['V'] = root.i\n",
    "        for child in root.children:\n",
    "            if child.dep_ == 'nsubj':\n",
    "                d['S'] = child.i\n",
    "            if child.dep_== 'dobj':\n",
    "                d['O'] = child.i\n",
    "        listt = sorted(d.keys(),key=d.get)\n",
    "        order = ''.join(listt)\n",
    "        orders.append(order)\n",
    "    return orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2de9b714-f794-4fb8-b449-2d7296845079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quotes_order(rows):\n",
    "    for row in rows:\n",
    "        row['word_order'] = word_order(row['Text'])\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "694aaf2f-23a6-4b6f-80ff-5f6fbdcadce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_list = '!\"«»“”#$%&\\–-–—()*+,./\\:;<=>?@[]^_`{|}~1234567890'\n",
    "\n",
    "def clean(text):\n",
    "    text = text.lower()\n",
    "    for char in text:\n",
    "        if char in punct_list:\n",
    "            text = text.replace(char, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cead469d-54d3-4ea5-8d55-c5b3e8d48978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def popular_words(rows):\n",
    "    txt_ps = []\n",
    "    txt_pe = []\n",
    "    txt_np = []\n",
    "    \n",
    "    populars = {'pricesses':{}, 'princes':{}, 'non-p':{}}\n",
    "\n",
    "    for row in rows:\n",
    "        # принцессы\n",
    "        if row['Speaker_Status'] == 'PRINCESS':\n",
    "            txt_ps.extend(extract_words(row['Text']))\n",
    "            \n",
    "        freq_ps = Counter(txt_ps)\n",
    "        freq_psSorted = sorted(freq_ps.items(), key = lambda x: x[1], reverse=True)\n",
    "        for i in freq_psSorted[:50]:\n",
    "            populars['pricesses'][i[0]] = freq_ps[i[0]]\n",
    "\n",
    "        # принцы\n",
    "        if row['Speaker_Status'] == 'PRINCE':\n",
    "            txt_pe.extend(extract_words(row['Text']))\n",
    "            \n",
    "            freq_pe = Counter(txt_pe)\n",
    "            freq_peSorted = sorted(freq_pe.items(), key = lambda x: x[1], reverse=True)\n",
    "            for i in freq_peSorted[:50]:\n",
    "                populars['princes'][i[0]] = freq_ps[i[0]]\n",
    "\n",
    "        # челядь\n",
    "        if row['Speaker_Status'] == 'NON-P':\n",
    "            txt_np.extend(extract_words(row['Text']))\n",
    "            \n",
    "            freq_np = Counter(txt_np)\n",
    "            freq_npSorted = sorted(freq_np.items(), key = lambda x: x[1], reverse=True)\n",
    "            for i in freq_npSorted[:50]:\n",
    "                populars['non-p'][i[0]] = freq_ps[i[0]]\n",
    "                \n",
    "    return populars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b04cee2-38d9-4dcc-b12a-1dcc8f55e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "with open('princess_corpus.csv', encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        row = dict(row)\n",
    "        rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6a8bb5-ee68-47bc-affb-4a6758e2445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pos(parse(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604c415f-3f92-477c-a241-ae1a2825bbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = phrase_len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1322b400-99c0-454f-8645-c04dd7565f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = quotes_order(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fb60cd-b938-4bae-a8d1-4b705b088350",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_dataset.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b23eb745-ea9c-4e28-a280-75c03a9ecd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция находящая полезные слова\n",
    "def extract_words(text):\n",
    "    words = clean(text).split()\n",
    "    good_words = []\n",
    "    for word in words:\n",
    "        if word not in stops:\n",
    "            good_words.append(word) \n",
    "    return good_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d3bf7a-1ca4-4200-8819-a9d179a9c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "populars = popular_words(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131f98ee-9619-4eeb-aca6-351731489f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(populars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
