{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acquired-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "impressive-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# чистка от пунктуации\n",
    "\n",
    "punct_list = '!\"«»“”#$%&\\–-–—()*+,./\\:;<=>?@[]^_`{|}~1234567890'\n",
    "\n",
    "def clean(text):\n",
    "    text = text.lower()\n",
    "    for char in text:\n",
    "        if char in punct_list:\n",
    "            text = text.replace(char, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "therapeutic-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops = stopwords.words('english')\n",
    "stops.extend([\"i'm\", \"he's\", \"i've\", \"i'll\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bulgarian-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.extend([\"i'm\", \"he's\", \"i've\", \"i'll\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# списки слов принцесс, принцов и не-пр\n",
    "\n",
    "txt_ps = []\n",
    "txt_pe = []\n",
    "txt_np = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "blessed-nurse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция: на вход строка — на выход список полезных слов (т. е. без стоп-слов и пунктуации)\n",
    "\n",
    "def extract_words(any_row):\n",
    "    words = clean(any_row).split()\n",
    "    good_words = []\n",
    "    for word in words:\n",
    "        if word not in stops:\n",
    "            good_words.append(word)\n",
    "                \n",
    "    return good_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "announced-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('princess_corpus.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        row = dict(row)\n",
    "        \n",
    "        # принцессы\n",
    "        if row['Speaker_Status'] == 'PRINCESS':\n",
    "            txt_ps.extend(extract_words(row['Text']))\n",
    "            \n",
    "        with open('princess.txt','a') as new_f:\n",
    "            stri = ' '.join(extract_words(row['Text'])) + '\\n'\n",
    "            new_f.write(stri)\n",
    "            \n",
    "        # принцы\n",
    "        if row['Speaker_Status'] == 'PRINCE':\n",
    "            txt_pe.extend(extract_words(row['Text']))\n",
    "            \n",
    "        # челядь\n",
    "        if row['Speaker_Status'] == 'NON-P':\n",
    "            txt_np.extend(extract_words(row['Text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eleven-belgium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oh \t 376\n",
      "know \t 208\n",
      "go \t 170\n",
      "come \t 148\n",
      "like \t 144\n",
      "never \t 142\n",
      "please \t 136\n",
      "see \t 136\n",
      "let \t 124\n",
      "get \t 118\n",
      "can't \t 114\n",
      "well \t 110\n",
      "want \t 104\n",
      "one \t 102\n",
      "right \t 102\n",
      "love \t 96\n",
      "wait \t 90\n",
      "yes \t 86\n",
      "back \t 86\n",
      "that's \t 78\n",
      "little \t 78\n",
      "got \t 78\n",
      "father \t 76\n",
      "would \t 74\n",
      "think \t 72\n",
      "mom \t 72\n",
      "look \t 70\n",
      "say \t 68\n",
      "sorry \t 68\n",
      "day \t 66\n",
      "time \t 66\n",
      "okay \t 64\n",
      "mean \t 62\n",
      "could \t 62\n",
      "away \t 60\n",
      "elsa \t 60\n",
      "help \t 58\n",
      "tell \t 56\n",
      "way \t 56\n",
      "prince \t 56\n",
      "around \t 56\n",
      "true \t 54\n",
      "going \t 54\n",
      "good \t 54\n",
      "thank \t 54\n",
      "gonna \t 54\n",
      "us \t 52\n",
      "find \t 50\n",
      "mother \t 50\n",
      "uh \t 50\n"
     ]
    }
   ],
   "source": [
    "#считаем популярные слова ПРИНЦЕСС\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "freq_ps = Counter(txt_ps)\n",
    "freq_psSorted = sorted(freq_ps.items(), key = lambda x: x[1], reverse=True)\n",
    "for i in freq_psSorted[:50]:\n",
    "    print(i[0], \"\\t\", freq_ps[i[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "incorporated-jungle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right \t 49\n",
      "well \t 44\n",
      "know \t 43\n",
      "one \t 42\n",
      "come \t 42\n",
      "get \t 42\n",
      "oh \t 39\n",
      "go \t 38\n",
      "can't \t 36\n",
      "like \t 36\n",
      "see \t 31\n",
      "look \t 31\n",
      "wait \t 29\n",
      "hey \t 26\n",
      "way \t 25\n",
      "abu \t 25\n",
      "yes \t 24\n",
      "really \t 24\n",
      "dad \t 24\n",
      "that's \t 23\n",
      "back \t 22\n",
      "yeah \t 22\n",
      "gonna \t 21\n",
      "never \t 20\n",
      "want \t 20\n",
      "uh \t 20\n",
      "would \t 19\n",
      "please \t 18\n",
      "prince \t 18\n",
      "find \t 18\n",
      "princess \t 18\n",
      "time \t 18\n",
      "let \t 18\n",
      "genie \t 18\n",
      "could \t 17\n",
      "make \t 17\n",
      "something \t 16\n",
      "sorry \t 16\n",
      "got \t 16\n",
      "tell \t 16\n",
      "jasmine \t 16\n",
      "mean \t 15\n",
      "king \t 15\n",
      "life \t 15\n",
      "love \t 14\n",
      "help \t 14\n",
      "we're \t 14\n",
      "going \t 13\n",
      "great \t 13\n",
      "huh \t 13\n"
     ]
    }
   ],
   "source": [
    "#считаем популярные слова ПРИНЦЕВ\n",
    "\n",
    "freq_pe = Counter(txt_pe)\n",
    "freq_peSorted = sorted(freq_pe.items(), key = lambda x: x[1], reverse=True)\n",
    "for i in freq_peSorted[:50]:\n",
    "    print(i[0], \"\\t\", freq_pe[i[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "allied-street",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oh \t 367\n",
      "get \t 212\n",
      "got \t 209\n",
      "like \t 200\n",
      "well \t 198\n",
      "come \t 196\n",
      "one \t 187\n",
      "go \t 178\n",
      "know \t 176\n",
      "yes \t 168\n",
      "right \t 151\n",
      "little \t 149\n",
      "see \t 146\n",
      "look \t 146\n",
      "that's \t 131\n",
      "love \t 129\n",
      "good \t 120\n",
      "time \t 110\n",
      "us \t 109\n",
      "make \t 104\n",
      "prince \t 104\n",
      "back \t 103\n",
      "can't \t 103\n",
      "take \t 102\n",
      "princess \t 97\n",
      "way \t 97\n",
      "let \t 96\n",
      "girl \t 95\n",
      "say \t 95\n",
      "uh \t 93\n",
      "think \t 90\n",
      "gonna \t 88\n",
      "king \t 87\n",
      "we're \t 85\n",
      "hey \t 83\n",
      "want \t 81\n",
      "dear \t 79\n",
      "going \t 77\n",
      "ah \t 76\n",
      "yeah \t 75\n",
      "man \t 75\n",
      "ha \t 75\n",
      "dig \t 74\n",
      "old \t 71\n",
      "never \t 70\n",
      "must \t 69\n",
      "day \t 68\n",
      "there's \t 67\n",
      "something \t 67\n",
      "tell \t 66\n"
     ]
    }
   ],
   "source": [
    "#считаем популярные слова НЕ-П\n",
    "\n",
    "freq_np = Counter(txt_np)\n",
    "freq_npSorted = sorted(freq_np.items(), key = lambda x: x[1], reverse=True)\n",
    "for i in freq_npSorted[:50]:\n",
    "    print(i[0], \"\\t\", freq_np[i[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Эта функция, которая принимает на вход датассет\n",
    "# и для каждой строки возвращает список полезных слов без пунктуации\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stops = stopwords.words('english')\n",
    "stops.extend([\"i'm\", \"he's\", \"i've\", \"i'll\"])\n",
    "\n",
    "# читска от пунктуации\n",
    "punct_list = '!\"«»“”#$%&\\–-–—()*+,./\\:;<=>?@[]^_`{|}~1234567890'\n",
    "\n",
    "def clean(text):\n",
    "    text = text.lower()\n",
    "    for char in text:\n",
    "        if char in punct_list:\n",
    "            text = text.replace(char, '')\n",
    "    return text\n",
    "\n",
    "# функция находящая полезные слова\n",
    "def extract_words(dataset):\n",
    "    df = pd.read_csv(dataset)\n",
    "    quotes = df['Text'].values\n",
    "    \n",
    "    for quot in quotes:\n",
    "        words = clean(quot).split()\n",
    "        good_words = []\n",
    "        for word in words:\n",
    "            if word not in stops:\n",
    "                good_words.append(word)\n",
    "                \n",
    "    return good_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}